{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: Pipeline ETL para processar os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cassandra-driver in c:\\users\\gilberto\\anaconda3\\lib\\site-packages (3.24.0)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\gilberto\\anaconda3\\lib\\site-packages (from cassandra-driver) (1.14.0)\n",
      "Requirement already satisfied: geomet<0.3,>=0.1 in c:\\users\\gilberto\\anaconda3\\lib\\site-packages (from cassandra-driver) (0.2.1.post1)\n",
      "Requirement already satisfied: click in c:\\users\\gilberto\\anaconda3\\lib\\site-packages (from geomet<0.3,>=0.1->cassandra-driver) (7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install cassandra-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando uma lista de caminhos para processar os arquivos originais e csv dos eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\Gilberto\\Desktop\\data_science\\data_engineering\\projeto_02\n",
      "C:\\Users\\Gilberto\\Desktop\\data_science\\data_engineering\\projeto_02/event_data\\2018-11-01-events.csv\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# Diretório atual\n",
    "print(f'Current working directory: {os.getcwd()}')\n",
    "\n",
    "# Diretório dos arquivos de eventos\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Cria uma lista de arquivos e coleta cada caminho\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    # Junta cada caminho e seu diretório raíz e subdiretórios usando o glob\n",
    "    file_path_list = glob.glob(os.path.join(root, '*'))\n",
    "\n",
    "print(file_path_list[0])\n",
    "print(len(file_path_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processando os arquivos em um csv que será utilizado nas tabelas do Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows : 8056\n",
      "Sample data:\n",
      " [['', 'Logged In', 'Walter', 'M', '0', 'Frye', '', 'free', 'San Francisco-Oakland-Hayward, CA', 'GET', 'Home', '1.54092E+12', '38', '', '200', '1.54111E+12', '39'], ['', 'Logged In', 'Kaylee', 'F', '0', 'Summers', '', 'free', 'Phoenix-Mesa-Scottsdale, AZ', 'GET', 'Home', '1.54034E+12', '139', '', '200', '1.54111E+12', '8'], [\"Des'ree\", 'Logged In', 'Kaylee', 'F', '1', 'Summers', '246.30812', 'free', 'Phoenix-Mesa-Scottsdale, AZ', 'PUT', 'NextSong', '1.54034E+12', '139', 'You Gotta Be', '200', '1.54111E+12', '8'], ['', 'Logged In', 'Kaylee', 'F', '2', 'Summers', '', 'free', 'Phoenix-Mesa-Scottsdale, AZ', 'GET', 'Upgrade', '1.54034E+12', '139', '', '200', '1.54111E+12', '8'], ['Mr Oizo', 'Logged In', 'Kaylee', 'F', '3', 'Summers', '144.03873', 'free', 'Phoenix-Mesa-Scottsdale, AZ', 'PUT', 'NextSong', '1.54034E+12', '139', 'Flat 55', '200', '1.54111E+12', '8']]\n"
     ]
    }
   ],
   "source": [
    "# Inicializando uma lista vazia que será preenchida com as linhas de cada arquivo\n",
    "full_data_rows_list = []\n",
    "\n",
    "# para cada caminho na nossa lista\n",
    "for f in file_path_list:\n",
    "    # lendo o arquivo csv\n",
    "    with open(f, 'r', encoding='utf8', newline='') as csvfile:\n",
    "        # cria um novo obj leitor de csv\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader)\n",
    "        \n",
    "        # extraindo os dados de cada linha\n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line)\n",
    "    \n",
    "print(f'Total rows : {len(full_data_rows_list)}')\n",
    "print(f'Sample data:\\n {full_data_rows_list[:5]}')\n",
    "\n",
    "# Criando um arquivo único de csv que será chamado pelas rotinas que transformarão ele em uma tabela do cassandra\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_data_processed.csv', 'w', encoding='utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist', 'firstName', 'gender', 'itemInSession', 'lastName', 'length', 'level', 'location', 'sessionId', 'song', 'userId'])\n",
    "    \n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# checando o numero de linhas no novo arquivo csv\n",
    "with open('event_data_processed.csv', 'r', encoding='utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agora podemos trabalhar com o arquivo de csv processado. Nele temos as seguintes colunas:\n",
    "\n",
    "- artist\n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docker\n",
    "```shell\n",
    "$ docker run --name cassandraDb -d -p 7199:7199 -p 7000:7000 -p 9042:9042 -p 9160:9160 -p 7001:7001 cassandra:3.11\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Established!\n"
     ]
    }
   ],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "\n",
    "try:\n",
    "    cluster = Cluster(['127.0.0.1'])\n",
    "    session = cluster.connect()\n",
    "    print('Connection Established!')\n",
    "except Exception as e:\n",
    "    print(f'Connection Failed. Error: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyspace_query = \"\"\"CREATE KEYSPACE IF NOT EXISTS sparkify\n",
    "    with REPLICATION =\n",
    "    { 'class': 'SimpleStrategy', 'replication_factor': 1 }\n",
    "\"\"\"\n",
    "\n",
    "# criando o keyspace\n",
    "try:\n",
    "    session.execute(keyspace_query)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create keyspace! Error : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolhendo o Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace('sparkify')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Próximo passo:\n",
    "\n",
    "Agora precisamos criar tabelas para executar as seguintes consultas. Lembre-se, com o Apache Cassandra, modelamos as tabelas do banco de dados nas consultas que queremos executar.\n",
    "Abaixo estão as consultas após as quais construiremos o modelo de dados:\n",
    "\n",
    "1. Forneça o artista, o título da música e a duração da música no histórico do aplicativo de música que foi ouvido durante `sessionId = 338` e `itemInSession = 4`.\n",
    "2. Dê apenas o seguinte: nome do artista, música (classificada por `itemInSession`) e usuário (nome e sobrenome) para `userid = 10`, `sessionid = 182`.\n",
    "3. Forneça todos os nomes de usuário (primeiro e último) no histórico do meu app de música que ouviram a música `'All Hands Against His Own'`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1\n",
    "\n",
    "Para a consulta 1, precisamos de uma forma de executar a consulta em sessionId e itemInSession. Portanto, nossa chave primária deve ter essas colunas. Podemos particionar os dados em sessionId.\n",
    "\n",
    "Nossa consulta Select: `SELECT artist, song, length FROM session_item WHERE sessionId = 338 AND itemInSession = 4`.\n",
    "\n",
    "Nossa chave primária será (sessionId, itemInSession), onde sessionId é a chave de partição e itemInSession é a coluna de cluster.\n",
    "Colunas que incluímos na tabela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created!\n"
     ]
    }
   ],
   "source": [
    "created_query1 = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS session_item (\n",
    "    artist text,\n",
    "    song text,\n",
    "    length float,\n",
    "    sessionId int,\n",
    "    itemInSession int,\n",
    "    PRIMARY KEY (sessionId, itemInSession)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    session.execute(created_query1)\n",
    "    print('Table created!')\n",
    "except Exception as e:\n",
    "    print(f'Table creation failed! Error {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_data_processed.csv'\n",
    "\n",
    "with open(file, encoding='utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # Pula o cabeçalho\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO session_item (artist, song, length, sessionId, itemInSession) \"\n",
    "        query += \" VALUES (%s, %s, %s, %s, %s) \"\n",
    "        session.execute(query, (line[0], line[10], float(line[5]), int(line[8]), int(line[3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELECT para verificar os dados que foram inseridos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Faithless', song='50', length=495.30731201171875)\n"
     ]
    }
   ],
   "source": [
    "select_query1 = \"SELECT artist, song, length FROM  session_item WHERE sessionId = 338 AND itemInSession = 4\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(select_query1)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 2\n",
    "\n",
    "Para a consulta 2, precisamos de uma maneira de executar a consulta em sessionId e userId. Além disso, precisamos dos dados classificados em itemInSession. Portanto, nossa chave primária deve ter essas colunas. Podemos particionar os dados em uma chave composta (sessionId, userId).\n",
    "\n",
    "Nossa consulta Select: `SELECT artist, song, firstName, lastName FROM user_session WHERE sessionId = 182 AND userId = 10`\n",
    "\n",
    "Nossa chave primária será ((sessionId, userId), itemInSession)), onde (sessionId, userId) é a chave de partição e itemInSession é a coluna de cluster.\n",
    "\n",
    "Além disso, estamos usando a cláusula - WITH CLUSTERING ORDER BY (itemInSession ASC), para classificar nossos dados com base em itemInSession.\n",
    "\n",
    "Colunas que incluímos na tabela: sessionId, userId, artist, song, firstName, lastName, itemInSession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Created!\n"
     ]
    }
   ],
   "source": [
    "create_query2 = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS user_session (\n",
    "    sessionId int, \n",
    "    userId int, \n",
    "    artist text, \n",
    "    song text, \n",
    "    firstName text, \n",
    "    lastName text, \n",
    "    itemInSession int, \n",
    "    PRIMARY KEY ((sessionId, userId), itemInSession)\n",
    ") WITH CLUSTERING ORDER BY (itemInSession ASC)\n",
    "\"\"\"\n",
    "\n",
    "try: \n",
    "    session.execute(create_query2)\n",
    "    print(\"Table Created!\")\n",
    "except Exception as e:\n",
    "    print(f\"Table creation failed! Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_data_processed.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_session (sessionId, userId, artist, song, firstName, lastName, itemInSession) \"\n",
    "        query += \" VALUES (%s, %s, %s, %s, %s, %s, %s) \"\n",
    "        session.execute(query, (int(line[8]), int(line[10]), line[0], line[9], line[1], line[4], int(line[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Down To The Bone', song=\"Keep On Keepin' On\", firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Three Drives', song='Greece 2000', firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Sebastien Tellier', song='Kilometer', firstname='Sylvie', lastname='Cruz')\n",
      "Row(artist='Lonnie Gordon', song='Catch You Baby (Steve Pitron & Max Sanna Radio Edit)', firstname='Sylvie', lastname='Cruz')\n"
     ]
    }
   ],
   "source": [
    "select_query2 = \"SELECT artist, song, firstName, lastName FROM  user_session where sessionId = 182 and userId = 10\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(select_query2)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 3\n",
    "\n",
    "Para a consulta 3, precisamos de uma maneira de executar a consulta na música. Então, nossa chave primária deve ter música. Além disso, a consulta deve ser tal que não contenha usuários duplicados para uma música. Portanto, precisamos modelar os dados de forma que não permitamos usuários duplicados para uma música em nossa mesa. Isso pode ser conseguido incluindo userId em nossa chave primária.\n",
    "\n",
    "Nossa consulta Select: `SELECT song, firstName, lastName FROM user_song WHERE song = 'All Hands Against His Own'`\n",
    "\n",
    "Nossa chave primária será ((song), userId)), onde song é a chave de partição e userId é a coluna de cluster.\n",
    "\n",
    "Colunas que incluímos na tabela: song, userId, firstName, lastName."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Created!\n"
     ]
    }
   ],
   "source": [
    "create_query3 = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS user_song (\n",
    "    song text, \n",
    "    userId int, \n",
    "    firstName text, \n",
    "    lastName text, \n",
    "    PRIMARY KEY ((song), userId)\n",
    ")\"\"\"\n",
    "\n",
    "try: \n",
    "    session.execute(create_query3)\n",
    "    print(\"Table Created!\")\n",
    "except Exception as e:\n",
    "    print(f\"Table creation failed! Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_data_processed.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    \n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_song (song, userId, firstName, lastName)\"\n",
    "        query += \" VALUES (%s, %s, %s, %s) \"\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(song='All Hands Against His Own', firstname='Jacqueline', lastname='Lynch')\n",
      "Row(song='All Hands Against His Own', firstname='Tegan', lastname='Levine')\n",
      "Row(song='All Hands Against His Own', firstname='Sara', lastname='Johnson')\n"
     ]
    }
   ],
   "source": [
    "select_query2 = \"SELECT song, firstName, lastName FROM user_song WHERE song = 'All Hands Against His Own'\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(select_query2)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excluindo as tabelas antes de fechar a conexão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationTimedOut",
     "evalue": "errors={'127.0.0.1:9042': 'Client request timeout. See Session.execute[_async](timeout)'}, last_host=127.0.0.1:9042",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationTimedOut\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-b57047a23df3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DROP TABLE IF EXISTS sparkify.session_item\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DROP TABLE IF EXISTS sparkify.user_session\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DROP TABLE IF EXISTS sparkify.user_song\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cassandra\\cluster.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mcassandra.cluster.Session.execute\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cassandra\\cluster.cp37-win_amd64.pyd\u001b[0m in \u001b[0;36mcassandra.cluster.ResponseFuture.result\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOperationTimedOut\u001b[0m: errors={'127.0.0.1:9042': 'Client request timeout. See Session.execute[_async](timeout)'}, last_host=127.0.0.1:9042"
     ]
    }
   ],
   "source": [
    "session.execute(\"DROP TABLE IF EXISTS sparkify.session_item\")\n",
    "session.execute(\"DROP TABLE IF EXISTS sparkify.user_session\")\n",
    "session.execute(\"DROP TABLE IF EXISTS sparkify.user_song\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fechando conexão e a sessão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
